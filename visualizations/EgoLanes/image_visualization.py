import os
import sys
import cv2
import numpy as np
from PIL import Image
from argparse import ArgumentParser

sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from inference.ego_lanes_infer import EgoLanesNetworkInfer
# from image_visualization import make_visualization

def make_visualization(image: np.ndarray, prediction: np.ndarray):
    """Draw lane predictions on the image."""
    
    img_h, img_w = image.shape[:2]
    _, ph, pw = prediction.shape
    scale_x = img_w / pw
    scale_y = img_h / ph

    img_bgr = cv2.cvtColor(image.copy(), cv2.COLOR_RGB2BGR)

    pred_coords = [np.where(prediction[c] > 0) for c in range(prediction.shape[0])]

    base_scale = min(scale_x, scale_y)
    radius = max(1, int(round(base_scale * 0.5)))

    colors = [
        (0, 72, 255),    # Blue (ego left)
        (200, 0, 255),   # Magenta (ego right)
        (0, 153, 0),     # Green (other lanes)
    ]

    for i, (ys, xs) in enumerate(pred_coords):
        if ys.size == 0:
            continue

        xs_scaled = (xs.astype(np.float32) * scale_x).astype(np.int32)
        ys_scaled = (ys.astype(np.float32) * scale_y).astype(np.int32)
        xs_scaled = np.clip(xs_scaled, 0, img_w - 1)
        ys_scaled = np.clip(ys_scaled, 0, img_h - 1)

        color = colors[i] if i < len(colors) else (255, 255, 255)
        for x, y in zip(xs_scaled, ys_scaled):
            cv2.circle(img_bgr, (int(x), int(y)), radius, color, thickness=-1, lineType=cv2.LINE_AA)

    return Image.fromarray(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))


def main():
    parser = ArgumentParser()
    parser.add_argument(
        "-p",
        "--model_checkpoint_path",
        dest="model_checkpoint_path",
        help="Path to Pytorch checkpoint file to load model dict",
        required=False
    )
    parser.add_argument(
        "-i",
        "--input_image_dirpath",
        dest="input_image_dirpath",
        help="Path to input image directory or single image which will be processed by EgoLanes",
        required=True
    )
    parser.add_argument(
        "-o",
        "--output_image_dirpath",
        dest="output_image_dirpath",
        help="Path to output image directory where visualizations will be saved",
        required=True
    )
    args = parser.parse_args()

    input_image_dirpath = args.input_image_dirpath
    output_image_dirpath = args.output_image_dirpath
    if not os.path.exists(output_image_dirpath):
        os.makedirs(output_image_dirpath)

    # Load model
    model_checkpoint_path = args.model_checkpoint_path if args.model_checkpoint_path else ""
    model = EgoLanesNetworkInfer(checkpoint_path=model_checkpoint_path)
    print("EgoLanes model successfully loaded!")

    # Determine if input is a file or folder
    if os.path.isfile(input_image_dirpath):
        image_files = [input_image_dirpath]
    elif os.path.isdir(input_image_dirpath):
        image_files = sorted([
            os.path.join(input_image_dirpath, f)
            for f in os.listdir(input_image_dirpath)
            if f.lower().endswith((".png", ".jpg", ".jpeg"))
        ])
    else:
        raise FileNotFoundError(f"No such file or directory: {input_image_dirpath}")

    if not image_files:
        print("No images found to process.")
        return

    # Process images
    for input_image_filepath in image_files:
        img_id = os.path.basename(input_image_filepath).split(".")[0].zfill(3)
        print(f"Reading Image: {input_image_filepath}")
        image = Image.open(input_image_filepath).convert("RGB")
        image = image.resize((640, 320))
        image = np.array(image)

        prediction = model.inference(image)
        vis_image = make_visualization(image.copy(), prediction)

        output_image_filepath = os.path.join(output_image_dirpath, f"{img_id}_data.png")
        vis_image.save(output_image_filepath)

    print(f"âœ… Processed {len(image_files)} image(s) into {output_image_dirpath}")


if __name__ == "__main__":
    main()

